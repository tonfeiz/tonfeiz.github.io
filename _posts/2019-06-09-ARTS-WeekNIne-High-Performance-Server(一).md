---
layout: posts
---
这篇英文文章讲的是高性能服务器设计的一些要点。  
原文链接为![High-Performance Server Architecture](http://pl.atyp.us/content/tech/servers.html)  

## Data Copies
数据拷贝可能被掩盖或是伪装。在第三方库中或是驱动中都可能进行许多数据拷贝。一个明显的例子是哈希。  

一种方法是使用缓冲区描述符而不是单纯的缓冲区指针。每个描述符由下列事项组成：  
* 一个指针以及缓冲区的长度  
* 一个指针或是偏移值以及长度。指针指向实际填充区域的开始，偏移也是，长度是实际填充的长度  
* 指向其他缓冲区的前向以及后向指针  
* 引用计数  

上述方法在某些情况下工作的很好，然而有时候也会让人头疼。这是因为在缓冲区链的前面和后面添加缓冲区是很方便的，但在中间添加缓冲区或是指向部分缓冲区等操作非常麻烦。  

作者不建议使用上述方法。最好的方法是识别出程序中的大对象并分别分配它们以避免拷贝。  

作者最后提醒，不要过分防止数据拷贝。过分防止数据拷贝可能导致代码变得更混乱、复杂。  

## Context Switches
当系统在线程间来回切换的时间比它在一个线程内干实际的活所消耗的时间还多时，上下文切换就严重拖慢了系统效率。  

造成上述现象的第一个原因是活跃线程数比处理器数量要多，因此可扩展的系统通常会限制活跃线程的数量。  

通常在前端需要使用select/poll,异步IO,信号或是completion ports等事件驱动机制来使得一个线程处理多个连接。  

最简单的多线程事件驱动服务器维护一个队列，每个请求被一个或多个`listeners`监听并放入队列，而`worker threads`从队列中取出任务。然而，这样做也会拖慢系统。上下文切换的第二个原因就是从一个线程到另一个线程传递任务。较好的设计应当是`listener`能变成`worker`再变回`listener`。  

如何限制活跃线程的数量呢？作者提出使用最简单的方法：信号量。活跃线程首先获取信号量再执行工作。  

作者接着提出，可以将对请求的处理分为多个阶段，通过阶段分发函数的返回值确定。例如:  
* 请求需要传给下一个阶段(ID或是指针作为返回值)  
* 请求已经被完成(特殊的"请求完成"返回值)  
* 请求被阻塞(特殊的"请求阻塞"返回值)。这和前面的阶段一样，但该请求未被释放，会在其他线程继续  
在上面的模型中，请求的排队在阶段内完成，而不是阶段之间。这避免了将请求压入成功阶段的队列然后进入成功阶段又取出  

作者最后对SEDA发表了自己的看法。  
* SEDA的批处理将多个请求通过一个阶段处理，作者提出的方法将单个请求通过多个阶段处理  
* 学术研究角度而言，用java完成SEDA是有意义的。实际工程中也许并不好  
